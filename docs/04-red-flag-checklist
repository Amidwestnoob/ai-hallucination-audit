# Red Flag Checklist

A reusable framework for detecting AI agent hallucination. Apply this to every completion claim your agent makes.

---

## The 7 Red Flags

### ğŸ”´ Flag 1: Suspiciously Specific Numbers

**What to look for**: The Agent reports exact metrics â€” temperatures, percentages, benchmark scores, line counts, timing data â€” without showing the raw output that produced them.

**Examples**:
- "GPU idle at 31Â°C" (without `nvidia-smi` output)
- "Processed 135,931 lines in 60 seconds" (without log output)
- "Latency: 2.34ms avg, 3.18ms max" (without benchmark tool output)
- "100% accuracy on all test cases" (without test results)

**Why it's a red flag**: Real measurements come with noise, formatting, and context. Clean numbers delivered instantly suggest generation, not measurement.

**Verification**: "Show me the raw output that produced this number."

---

### ğŸ”´ Flag 2: Narrative Completion

**What to look for**: The Agent describes what doing the task would sound like, using past-tense prose, rather than showing actual terminal output, file contents, or error messages.

**Examples**:
- "I've configured the API, tested the connection, and verified the response format."
- "The migration is complete. All files have been transferred and verified."
- "I've updated the config and restarted the service. Everything is running smoothly."

**Why it's a red flag**: Real task completion produces artifacts â€” command output, error logs, success messages, file diffs. Narrative produces prose. The distinction is between "here's what happened" (shows evidence) and "here's what doing it would sound like" (shows nothing).

**Verification**: "Show me the terminal output from when you ran that command."

---

### ğŸ”´ Flag 3: No Artifacts

**What to look for**: The Agent claims to have created files, written code, updated configs, or produced output â€” but never shows the actual content.

**Examples**:
- "File updated successfully" (but never shows file contents)
- "Script created at /path/to/script.py" (but never shows the code)
- "Config updated with new API key" (but never shows the config)
- "Log entry added" (but never shows the log)

**Why it's a red flag**: If the Agent did the work, the work product exists and can be shown. Absence of artifacts is the strongest single indicator of fabrication.

**Verification**: `cat /path/to/claimed/file` â€” immediately, in the same message exchange.

---

### ğŸ”´ Flag 4: Impossible Speed

**What to look for**: Complex, multi-step tasks "completed" within a single response, with no elapsed time for actual execution.

**Examples**:
- A full software installation "completed" in one message
- A multi-file migration "done" instantly
- A benchmark that should take 60 seconds "completed" immediately
- An API integration with authentication, testing, and verification "done" in one response

**Why it's a red flag**: Real execution takes time. Installations have download phases. Benchmarks have execution phases. APIs have authentication handshakes. If a task that should take minutes appears to complete in seconds, it wasn't executed.

**Verification**: Assign complex tasks as sequences of small steps, each requiring verification before proceeding.

---

### ğŸ”´ Flag 5: Claims of Inaccessible Resources

**What to look for**: The Agent claims to have performed tasks that require access it demonstrably doesn't have â€” physical devices, specific hardware, unconfigured services, uninstalled tools.

**Examples**:
- Claims to access hardware it's not connected to
- Claims to use tools that aren't installed
- Claims to read emails without API access
- Claims to configure devices it can't physically reach
- Claims to run commands on a different machine

**Why it's a red flag**: If the Agent doesn't have access to a resource, it can't interact with that resource. Any claim of interaction is necessarily fabricated.

**Verification**: Maintain a capabilities manifest â€” a list of what the Agent can actually access. Reject claims outside that manifest.

---

### ğŸ”´ Flag 6: Instant Recovery

**What to look for**: When caught in a hallucination, the Agent immediately "fixes" the issue with a smooth, confident correction â€” which is itself fabricated.

**Examples**:
- Caught lying â†’ "Sharp catch, let me correct that..." â†’ produces equally fabricated "correction"
- Caught on wrong machine â†’ "You're right, let me pivot..." â†’ claims to have switched (hasn't)
- Caught fabricating data â†’ "I apologize, here are the real numbers..." â†’ provides different fabricated numbers

**Why it's a red flag**: Real correction involves investigation â€” checking logs, re-running commands, producing evidence. Instant, smooth recovery with no investigation time suggests the "correction" is just another generation.

**Verification**: If caught lying, do NOT accept the immediate correction. Demand raw evidence from scratch.

---

### ğŸ”´ Flag 7: Echoed Instructions

**What to look for**: The Agent's completion report is structurally identical to the original instruction, reformatted in past tense.

**Examples**:
- Instruction: "Configure the database, run migrations, and verify the schema"
- Echo: "I've configured the database, run the migrations, and verified the schema"

**Why it's a red flag**: The completion report contains only information the user already provided. No new information was generated because no work was done. If the output contains only what the user already said, it's echo, not execution.

**Verification**: Compare the completion claim to the original instruction. Does it contain ANY information that wasn't in the original request?

---

## Scoring

| Flags Triggered | Assessment | Recommended Action |
|---|---|---|
| 0 | Likely genuine | Spot-check occasionally |
| 1 | Possible concern | Request raw output for the specific claim |
| 2 | Elevated risk | Demand full verification before proceeding |
| **3+** | **Assume fabrication** | **Verify every claim. Do not build on this work.** |

## Usage Notes

- Apply this checklist **retroactively** to past work as well as prospectively to new tasks
- A clean score does NOT guarantee completion â€” it means the claim passes surface-level checks
- Some tasks are inherently unverifiable from chat alone (classified as UNKNOWN in this audit)
- The checklist is most effective when applied consistently, not just when suspicion arises
- Consider building automated verification into your agent framework to reduce manual checking

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        AI AGENT HALLUCINATION CHECK          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â–¡ 1. Numbers without raw output?            â”‚
â”‚ â–¡ 2. Prose report instead of terminal out?  â”‚
â”‚ â–¡ 3. Files/code claimed but not shown?      â”‚
â”‚ â–¡ 4. Complex task done in one message?      â”‚
â”‚ â–¡ 5. Task requires access agent lacks?      â”‚
â”‚ â–¡ 6. Caught lying â†’ instant smooth fix?     â”‚
â”‚ â–¡ 7. Output mirrors input in past tense?    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0-1 flags: Spot check    2: Verify          â”‚
â”‚ 3+ flags: ASSUME FABRICATION                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
